{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reducers = ee.Reducer.mean().combine(**\n",
    "                                     {'reducer2': ee.Reducer.stdDev(), \n",
    "                                      'sharedInputs': True}).combine(**\n",
    "                                                                     {'reducer2': ee.Reducer.max(), \n",
    "                                                                      'sharedInputs': True}).combine(**\n",
    "                                                                                                     {'reducer2':ee.Reducer.min(), \n",
    "                                                                                                      'sharedInputs':True}).combine(**\n",
    "                                                                                                                                    {'reducer2': ee.Reducer.percentile([25, 50, 75]), \n",
    "                                                                                                                                     'sharedInputs':True})\n",
    "def det(im):\n",
    "    return im.expression('b(0) * b(1)')\n",
    "    \n",
    "def chi2cdf(chi2, df):\n",
    "    ''' Chi square cumulative distribution function for df degrees of freedom\n",
    "    using the built-in incomplete gamma function gammainc() '''\n",
    "    return ee.Image(chi2.divide(2)).gammainc(ee.Number(df).divide(2))\n",
    "\n",
    "def sar(before, after, geometry): \n",
    "    m = 5\n",
    "    \n",
    "    try:\n",
    "        # The observed test statistic image -2logq\n",
    "        m2logq = det(before).log().add(det(after).log()).subtract(det(before.add(after)).log().multiply(2)).add(4*np.log(2)).multiply(-2*m)\n",
    "        \n",
    "        # The P value image prob(m2logQ > m2logq) = 1 - prob(m2logQ < m2logq).\n",
    "        p_value = ee.Image.constant(1).subtract(chi2cdf(m2logq, 2))\n",
    "        \n",
    "        c_map = p_value.multiply(0).where(p_value.lt(0.05), 1)\n",
    "        \n",
    "        diff = after.subtract(before) # Getting the difference between the two images\n",
    "        d_map = c_map.multiply(0)                    # Initialize the direction map to zero.\n",
    "        d_map = d_map.where(det(diff).gt(0), 1)      # All pos or neg def diffs are now labeled 1.\n",
    "        d_map = d_map.where(diff.select(0).gt(0), 2) # Re-label pos def (and label some indef) to 2.\n",
    "        d_map = d_map.where(det(diff).lt(0), 1)      # Label all indef to 1.\n",
    "        c_map = c_map.multiply(d_map) # Re-label the c_map, 0*X = 0, 1*1 = 1, 1*2= 2, 1*3 = 3.\n",
    "        \n",
    "        stats = c_map.reduceRegion(**{'reducer':reducers, 'bestEffort':True, 'scale':30, 'geometry':geometry}).getInfo()\n",
    "        mean = stats['constant_mean']\n",
    "        stddev = stats['constant_stdDev']\n",
    "        p25 = stats['constant_p25']\n",
    "        p50 = stats['constant_p50']\n",
    "        p75 = stats['constant_p75']\n",
    "        mini = stats['constant_min']\n",
    "        maxi = stats['constant_max']\n",
    "        \n",
    "    except: \n",
    "        mean = None\n",
    "        stddev = None\n",
    "        p25 = None\n",
    "        p50 = None\n",
    "        p75 = None\n",
    "        min = None\n",
    "        max = None\n",
    "        \n",
    "    return p25, p50, p75, mean, stddev, mini, maxi\n",
    "\n",
    "def nbr(before, after, geometry):\n",
    "    try:\n",
    "        stats_b = before.normalizedDifference(['B5', 'B7']).rename('NBR').reduceRegion(**{'reducer':reducers,\n",
    "                                                                                          'bestEffort':True, 'scale':30, 'geometry':geometry}).getInfo()\n",
    "        stats_a = after.normalizedDifference(['B5', 'B7']).rename('NBR').reduceRegion(**{'reducer':reducers,\n",
    "                                                                                         'bestEffort':True, 'scale':30, 'geometry':geometry}).getInfo()\n",
    "\n",
    "        mean_b = stats_b['NBR_mean']\n",
    "        mean_a = stats_a['NBR_mean']\n",
    "\n",
    "        p25_b = stats_b['NBR_p25']\n",
    "        p25_a = stats_a['NBR_p25']\n",
    "\n",
    "        p50_b = stats_b['NBR_p50']\n",
    "        p50_a = stats_a['NBR_p50']\n",
    "\n",
    "        p75_b = stats_b['NBR_p75']\n",
    "        p75_a = stats_a['NBR_p75']\n",
    "\n",
    "        stddev_b = stats_b['NBR_stdDev']\n",
    "        stddev_a = stats_a['NBR_stdDev']\n",
    "\n",
    "        min_b = stats_b['NBR_min']\n",
    "        min_a = stats_a['NBR_min']\n",
    "\n",
    "        max_b = stats_b['NBR_max']\n",
    "        max_a = stats_a['NBR_max']\n",
    "\n",
    "        p25 = p25_a - p25_b * 100\n",
    "        p50 = p50_a - p50_b * 100\n",
    "        p75 = p75_a - p50_b * 100\n",
    "        mean = mean_a - mean_b * 100\n",
    "        mini = min_a - min_b * 100\n",
    "        maxi = max_a - max_b * 100\n",
    "        stddev = stddev_a - stddev_b * 100\n",
    "  \n",
    "    except: \n",
    "        p25 = None\n",
    "        p50 = None\n",
    "        p75 = None\n",
    "        mean = None\n",
    "        stddev = None\n",
    "        mini = None\n",
    "        maxi = None\n",
    "    \n",
    "    return p25, p50, p75, mean, stddev, mini, maxi\n",
    "\n",
    "def ndvi(before, after, geometry):\n",
    "    \n",
    "    try:\n",
    "        stats_b = before.normalizedDifference(['B5', 'B4']).rename('NDVI').reduceRegion(**{'reducer':reducers,\n",
    "                                                                                           'bestEffort':True, 'scale':30, 'geometry':geometry}).getInfo()\n",
    "        \n",
    "        stats_a = after.normalizedDifference(['B5', 'B4']).rename('NDVI').reduceRegion(**{'reducer':reducers,\n",
    "                                                                                          'bestEffort':True, 'scale':30, 'geometry':geometry}).getInfo()\n",
    "\n",
    "        mean_b = stats_b['NDVI_mean']\n",
    "        mean_a = stats_a['NDVI_mean']\n",
    "\n",
    "        p25_b = stats_b['NDVI_p25']\n",
    "        p25_a = stats_a['NDVI_p25']\n",
    "\n",
    "        p50_b = stats_b['NDVI_p50']\n",
    "        p50_a = stats_a['NDVI_p50']\n",
    "\n",
    "        p75_b = stats_b['NDVI_p75']\n",
    "        p75_a = stats_a['NDVI_p75']\n",
    "\n",
    "        stddev_b = stats_b['NDVI_stdDev']\n",
    "        stddev_a = stats_a['NDVI_stdDev']\n",
    "\n",
    "        min_b = stats_b['NDVI_min']\n",
    "        min_a = stats_a['NDVI_min']\n",
    "\n",
    "        max_b = stats_b['NDVI_max']\n",
    "        max_a = stats_a['NDVI_max']\n",
    "\n",
    "        p25 = p25_a - p25_b * 100\n",
    "        p50 = p50_a - p50_b * 100\n",
    "        p75 = p75_a - p50_b * 100\n",
    "        mean = mean_a - mean_b * 100\n",
    "        mini = min_a - min_b * 100\n",
    "        maxi = max_a - max_b * 100\n",
    "        stddev = stddev_a - stddev_b * 100 \n",
    "  \n",
    "    except: \n",
    "        p25 = None\n",
    "        p50 = None\n",
    "        p75 = None\n",
    "        mean = None\n",
    "        stddev = None\n",
    "        mini = None\n",
    "        maxi = None\n",
    "    \n",
    "    return p25, p50, p75, mean, stddev, mini, maxi\n",
    "\n",
    "def evi(before, after, geometry):\n",
    "    try:\n",
    "        before_evi = before.expression(\n",
    "            '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
    "                'NIR': before.select('B5'),\n",
    "                'RED': before.select('B4'),\n",
    "                'BLUE': before.select('B2')})\n",
    "\n",
    "        after_evi = after.expression(\n",
    "            '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
    "                'NIR': after.select('B5'),\n",
    "                'RED': after.select('B4'),\n",
    "                'BLUE': after.select('B2')})\n",
    "\n",
    "        stats_b = before_evi.rename('EVI').reduceRegion(**{'reducer':reducers, 'bestEffort':True, 'scale':30, 'geometry':geometry}).getInfo()\n",
    "        stats_a = after_evi.rename('EVI').reduceRegion(**{'reducer':reducers, 'bestEffort':True, 'scale':30, 'geometry':geometry}).getInfo()\n",
    "\n",
    "        mean_b = stats_b['EVI_mean']\n",
    "        mean_a = stats_a['EVI_mean']\n",
    "\n",
    "        p25_b = stats_b['EVI_p25']\n",
    "        p25_a = stats_a['EVI_p25']\n",
    "\n",
    "        p50_b = stats_b['EVI_p50']\n",
    "        p50_a = stats_a['EVI_p50']\n",
    "\n",
    "        p75_b = stats_b['EVI_p75']\n",
    "        p75_a = stats_a['EVI_p75']\n",
    "\n",
    "        stddev_b = stats_b['EVI_stdDev']\n",
    "        stddev_a = stats_a['EVI_stdDev']\n",
    "\n",
    "        min_b = stats_b['EVI_min']\n",
    "        min_a = stats_a['EVI_min']\n",
    "\n",
    "        max_b = stats_b['EVI_max']\n",
    "        max_a = stats_a['EVI_max']\n",
    "\n",
    "        p25 = p25_a - p25_b * 100\n",
    "        p50 = p50_a - p50_b * 100\n",
    "        p75 = p75_a - p50_b * 100\n",
    "        mean = mean_a - mean_b * 100\n",
    "        mini = min_a - min_b * 100\n",
    "        maxi = max_a - max_b * 100\n",
    "        stddev = stddev_a - stddev_b * 100\n",
    "  \n",
    "    except: \n",
    "        p25 = None\n",
    "        p50 = None\n",
    "        p75 = None\n",
    "        mean = None\n",
    "        stddev = None\n",
    "        mini = None\n",
    "        maxi = None\n",
    "    \n",
    "    return p25, p50, p75, mean, stddev, mini, maxi\n",
    "\n",
    "def difference(coordinate, date):\n",
    "    \n",
    "    point = ee.Geometry.Point(coordinate.getInfo()['features'][0]['geometry']['coordinates'])\n",
    "    geometry = point.buffer(1000) # buffers point by 1 km\n",
    "\n",
    "    md = ee.Date(date)\n",
    "    sd = md.advance(-4, 'week')\n",
    "    ed = md.advance(4, 'week')\n",
    "\n",
    "    before_sar = ee.ImageCollection(\"COPERNICUS/S1_GRD_FLOAT\").filterBounds(c).filterDate(sd, md).filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING')).limit(1, 'system:time_start', False).first() \n",
    "    aafter_sar = ee.ImageCollection(\"COPERNICUS/S1_GRD_FLOAT\").filterBounds(c).filterDate(md, ed).filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING')).first()\n",
    "\n",
    "        \n",
    "    before_landsat = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').filterBounds(c).filterDate(sd, md).sort('CLOUD_COVER').limit(1, 'system:time_start', False).first()\n",
    "    after_landsat = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').filterBounds(c).filterDate(md, ed).sort('CLOUD_COVER').first()\n",
    "    \n",
    "    ndvi_p25, ndvi_p50, ndvi_p75, ndvi_mean, ndvi_stddev, ndvi_min, ndvi_max = ndvi(before_landsat, \n",
    "                                                                                    after_landsat, \n",
    "                                                                                    geometry)  \n",
    "\n",
    "    evi_p25, evi_p50, evi_p75, evi_mean, evi_stddev, evi_min, evi_max = evi(before_landsat, \n",
    "                                                                            after_landsat, \n",
    "                                                                            geometry)\n",
    "\n",
    "    sar_p25, sar_p50, sar_p75, sar_mean, sar_stddev, sar_min, sar_max = sar(before_sar, \n",
    "                                                                            \n",
    "                                                                            after_sar, geometry)\n",
    "\n",
    "    nbr_p25_, nbr_p50, nbr_p75, nbr_mean, nbr_stddev, nbr_min, nbr_max = nbr(before_landsat, \n",
    "                                                                             after_landsat, \n",
    "                                                                             geometry)\n",
    "\n",
    "    \n",
    "    ar = np.array([ndvi_p25, ndvi_p50, ndvi_p75, ndvi_mean, ndvi_min, ndvi_max, \n",
    "                   evi_p25, evi_p50, evi_p75, evi_mean, evi_stddev, evi_min, evi_max, \n",
    "                   sar_mean, sar_stddev, sar_max, \n",
    "                   nbr_mean, nbr_stddev, nbr_p25_, nbr_p50, nbr_p75, nbr_min])\n",
    "\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "cols = data.columns\n",
    "data[cols] = data[cols].apply(pd.to_numeric, errors='coerce')\n",
    "data.drop(columns=['Unnamed: 0', 'SAR_p75', 'SAR_min', 'SAR_p50', 'SAR_p25', 'NDVI_stdDev'], inplace=True)\n",
    "data.dropna(how='any', axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, :-2]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7368, 22)\n",
      "(7368,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\miniconda3\\envs\\ds\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass solver=sgd, alpha=0.01, batch_size=50, learning_rate=adaptive, learning_rate_init=0.1, power_t=250 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([('Scale', StandardScaler()), \n",
    "                       ('PCA', PCA(n_components = 14, random_state=1)), \n",
    "                        ('Classifier', MLPClassifier((400,200), 'relu', 'sgd', 0.01, 50, 'adaptive', 0.1, 250, random_state=0, early_stopping=True, n_iter_no_change=5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1. 1. 1. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-f005b4994684>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\ds\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ds\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ds\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m         X = self._validate_data(X, reset=False,\n\u001b[0m\u001b[0;32m    884\u001b[0m                                 \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ds\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ds\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ds\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    638\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1. 1. 1. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "classifier.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.878800217155266"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pickle.dumps(classifier)\n",
    "clf = pickle.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Scale', StandardScaler()),\n",
       "                ('PCA', PCA(n_components=14, random_state=1)),\n",
       "                ('Classifier',\n",
       "                 MLPClassifier(alpha=0.01, batch_size=50, early_stopping=True,\n",
       "                               hidden_layer_sizes=(400, 200),\n",
       "                               learning_rate='adaptive', learning_rate_init=0.1,\n",
       "                               n_iter_no_change=5, power_t=250, random_state=0,\n",
       "                               solver='sgd'))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
